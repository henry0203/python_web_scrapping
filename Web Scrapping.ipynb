{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scrapping basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\r\\n  <head>\\r\\n      <title> Un exemple de page HTML </title>\\r\\n  </head>\\r\\n\\r\\n  <body>\\r\\n      <p>Un simple paragraphe</p>\\r\\n  </body>\\r\\n</html>'\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://raw.githubusercontent.com/codelikerod/web-scraping/master/exemple1.html\")\n",
    "content = response.content\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET page element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib beautifulSoup of package bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un simple paragraphe\n",
      " Un exemple de page HTML \n"
     ]
    }
   ],
   "source": [
    "# apply BeautifulSoup to analyze content previously downloaded\n",
    "parser = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "# Get body tag of the HTML document\n",
    "body = parser.body\n",
    "head = parser.head\n",
    "\n",
    "# Get tag p of the body\n",
    "p = body.p\n",
    "title = head.title\n",
    "\n",
    "# Display text -> use attribute .text\n",
    "print(p.text)\n",
    "print(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Find All method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<body>\n",
      "<p>Un simple paragraphe</p>\n",
      "</body>]\n",
      "[<head>\n",
      "<title> Un exemple de page HTML </title>\n",
      "</head>]\n",
      "Un simple paragraphe\n",
      " Un exemple de page HTML \n"
     ]
    }
   ],
   "source": [
    "parser = BeautifulSoup(content,\"html.parser\")\n",
    "\n",
    "# Get all element of body section\n",
    "body = parser.find_all(\"body\")\n",
    "print(body)\n",
    "head = parser.find_all(\"head\")\n",
    "print(head)\n",
    "\n",
    "#Get elements of p/ title section in body/head section\n",
    "p = body[0].find_all(\"p\") # body[0] because we get the first list element\n",
    "print(p[0].text)\n",
    "title = head[0].find_all(\"title\") # head[0] because we get the first list element\n",
    "print(title[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements related to IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\r\\n  <head>\\r\\n      <title> Un exemple de page HTML </title>\\r\\n  </head>\\r\\n\\r\\n  <body>\\r\\n    <div>\\r\\n      <p id=\"first\">1er paragraphe</p>\\r\\n    </div>\\r\\n      <p id=\"second\">2nd paragraphe</p>\\r\\n  </body>\\r\\n</html>'\n",
      "1er paragraphe\n",
      "2nd paragraphe\n"
     ]
    }
   ],
   "source": [
    "#Download page\n",
    "response = requests.get(\"https://raw.githubusercontent.com/codelikerod/web-scraping/master/exemple2.html\")\n",
    "content = response.content\n",
    "print(content)\n",
    "parser = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "#Get ID requested\n",
    "first_paragraph = parser.find_all(\"p\", id=\"first\")[0] #We add ID = first\n",
    "print(first_paragraph.text)\n",
    "second_paragraph = parser.find_all(\"p\", id=\"second\")[0] #We add ID = first\n",
    "print(second_paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements related to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\r\\n  <head>\\r\\n      <title> Un exemple de page HTML </title>\\r\\n  </head>\\r\\n\\r\\n  <body>\\r\\n    <div>\\r\\n      <p class=\"class1\">1er paragraphe classe 1</p>\\r\\n      <p class=\"class1\">2nd paragraphe class 1</p>\\r\\n    </div>\\r\\n      <p class=\"class2\">1er paragraphe class 2</p>\\r\\n      <p class=\"class2\">2nd paragraphe class 2</p>\\r\\n  </body>\\r\\n</html>'\n",
      "1er paragraphe classe 1\n",
      "2nd paragraphe class 1\n",
      "1er paragraphe class 2\n"
     ]
    }
   ],
   "source": [
    "#Download web page\n",
    "response = requests.get(\"https://raw.githubusercontent.com/codelikerod/web-scraping/master/exemple3.html\")\n",
    "content = response.content\n",
    "print(content)\n",
    "parser = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "#Get first paragraph of class1\n",
    "first_class1_paragraph = parser.find_all(\"p\", class_=\"class1\")[0] #We add ID = first\n",
    "print(first_class1_paragraph.text)\n",
    "second_class1_paragraph = parser.find_all(\"p\", class_=\"class1\")[1] #We add ID = first\n",
    "print(second_class1_paragraph.text)\n",
    "first_class2_paragraph = parser.find_all(\"p\", class_=\"class2\")[0] #We add ID = first\n",
    "print(first_class2_paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements selected with CSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #first { color: red }\n",
    "# .class1 { color: red }\n",
    "# select "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1er paragraphe classe 1\r\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "#Download page\n",
    "response = requests.get(\"https://raw.githubusercontent.com/codelikerod/web-scraping/master/exemple4.html\")\n",
    "content = response.content\n",
    "#print(content)\n",
    "parser = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "#Get all element of class first-item\n",
    "first_items = parser.select(\".first-item\") \n",
    "print(first_items[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1er paragraphe class 2\r\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "first_class2_text = parser.select(\".class2\")[0].text\n",
    "print(first_class2_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1er paragraphe class 2\r\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "second_text = parser.select(\"#second\")[0].text\n",
    "print(second_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associate CSS selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# div p \n",
    "# div .first-item\n",
    "# body div #first\n",
    "# .first-item #first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head lang=\"en\">\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>PSG - Chelsea</title>\n",
      "</head>\n",
      "<body>\n",
      "<table class=\"stats_table nav_table\" id=\"team_stats\">\n",
      "<tbody>\n",
      "<tr id=\"teams\">\n",
      "<th></th>\n",
      "<th>Chelsea</th>\n",
      "<th>Paris</th>\n",
      "</tr>\n",
      "<tr id=\"goals\">\n",
      "<td>Buts</td>\n",
      "<td>2</td>\n",
      "<td>2</td>\n",
      "</tr>\n",
      "<tr id=\"possession\">\n",
      "<td>Possession</td>\n",
      "<td>51%</td>\n",
      "<td>49%</td>\n",
      "</tr>\n",
      "<tr id=\"tirs\">\n",
      "<td>Nombre de tirs</td>\n",
      "<td>14</td>\n",
      "<td>12</td>\n",
      "</tr>\n",
      "<tr id=\"corners\">\n",
      "<td>Nombre de corners</td>\n",
      "<td>7</td>\n",
      "<td>11</td>\n",
      "</tr>\n",
      "<tr id=\"fautes\">\n",
      "<td>Fautes</td>\n",
      "<td>24</td>\n",
      "<td>17</td>\n",
      "</tr>\n",
      "<tr id=\"passes\">\n",
      "<td>Nombre de passes</td>\n",
      "<td>537</td>\n",
      "<td>545</td>\n",
      "</tr>\n",
      "</tbody>\n",
      "</table>\n",
      "</body>\n",
      "</html>\n",
      "24\n",
      "545\n"
     ]
    }
   ],
   "source": [
    "#Download page\n",
    "response = requests.get(\"https://raw.githubusercontent.com/codelikerod/web-scraping/master/psg-vs-chelsea.html\")\n",
    "content = response.content\n",
    "#print(content)\n",
    "parser = BeautifulSoup(content, \"html.parser\")\n",
    "print(parser)\n",
    "\n",
    "#Get Chelsea faults numbers\n",
    "offences = parser.select(\"#fautes\")[0]\n",
    "chelsea_offences = offences.select(\"td\")[1]\n",
    "print(chelsea_offences.text)\n",
    "\n",
    "#Get number of passes succeeded\n",
    "psg_pass_count = parser.select(\"#passes\")[0].select(\"td\")[2].text\n",
    "print(psg_pass_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
